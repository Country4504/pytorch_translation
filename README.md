# 英文到中文机器翻译项目

这是一个基于PyTorch实现的英文到中文机器翻译项目，使用了Seq2Seq模型和注意力机制。

## 项目结构

```
pytorch实训/
├── train.py          # 训练脚本
├── test.py           # 测试脚本
├── models.py         # 模型定义
├── datasets.py       # 数据处理
├── utils.py          # 工具函数
├── langconv.py       # 中文繁简转换
├── zh_wiki.py        # 繁简对照表
├── requirements.txt  # 依赖包
├── README.md         # 项目说明
├── data/             # 数据目录
│   └── cmn.txt       # 英文-中文平行语料
└── models/           # 模型保存目录
```

## 环境要求

- Python 3.7+
- PyTorch 1.9.0+
- CUDA (可选，用于GPU加速)

## 安装步骤

1. **安装依赖包**：
```bash
pip install -r requirements.txt
```

2. **准备数据**：
   - 确保 `data/cmn.txt` 文件存在
   - 数据格式：英文句子\t中文句子（用Tab分隔）

3. **创建模型保存目录**：
   - 确保 `models/` 目录存在

## 运行步骤

### 第一步：训练模型
```bash
python train.py
```

**训练过程说明**：
- 训练10000次迭代
- 每1000次打印训练进度
- 每10000次保存模型
- 使用教师强制策略提高训练效率
- 学习率每1000步自动调整

**训练输出示例**：
```
0m 15s (- 2m 25s) 1000 10.0% 2.1234
0m 30s (- 2m 10s) 2000 20.0% 1.8765
...
```

### 第二步：测试模型
```bash
python test.py
```

**测试过程说明**：
- 加载训练好的模型（models/encoder_10000.pth, models/decoder_10000.pth）
- 随机选择10个样本进行翻译测试
- 显示原文、标准译文和预测结果

**测试输出示例**：
```
原文：what are you doing?
标准译文：你 在 干 什么
预测结果：['你', '在', '做', '什么', '<EOS>']
```

## 模型架构

- **编码器**：GRU网络，将英文句子编码为隐藏状态
- **解码器**：带注意力机制的GRU网络，生成中文翻译
- **注意力机制**：帮助模型关注输入句子的不同部分
- **词嵌入**：将词汇转换为向量表示

## 数据处理

- **英文处理**：小写化、去除非字母字符
- **中文处理**：繁体转简体、jieba分词
- **长度限制**：过滤超过10个词的句子
- **词汇表**：自动构建英文和中文词汇表

## 注意事项

1. **数据格式**：确保训练数据格式正确（英文\t中文）
2. **GPU使用**：如果有CUDA，会自动使用GPU加速
3. **模型保存**：训练过程中会自动保存模型到models/目录
4. **内存使用**：大数据集可能需要较多内存

## 自定义配置

可以在代码中修改以下参数：
- `hidden_size`：隐藏层大小（默认256）
- `n_iters`：训练迭代次数（默认10000）
- `lr`：学习率（默认0.01）
- `MAX_LENGTH`：最大句子长度（默认10）

## 故障排除

1. **CUDA错误**：如果没有GPU，代码会自动使用CPU
2. **内存不足**：减少batch_size或使用更小的hidden_size
3. **数据路径错误**：检查data/cmn.txt文件是否存在
4. **依赖包错误**：重新安装requirements.txt中的包 